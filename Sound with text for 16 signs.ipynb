{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72962375",
   "metadata": {},
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4edc5100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data for class 0\n",
      "Collecting data for class 1\n",
      "Collecting data for class 2\n",
      "Collecting data for class 3\n",
      "Collecting data for class 4\n",
      "Collecting data for class 5\n",
      "Collecting data for class 6\n",
      "Collecting data for class 7\n",
      "Collecting data for class 8\n",
      "Collecting data for class 9\n",
      "Collecting data for class 10\n",
      "Collecting data for class 11\n",
      "Collecting data for class 12\n",
      "Collecting data for class 13\n",
      "Collecting data for class 14\n",
      "Collecting data for class 15\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "DATA_DIR = './data'\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "\n",
    "number_of_classes = 16\n",
    "dataset_size = 100\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "for j in range(number_of_classes):\n",
    "\n",
    "    if not os.path.exists(os.path.join(DATA_DIR, str(j))):\n",
    "        os.makedirs(os.path.join(DATA_DIR, str(j)))\n",
    "\n",
    "    print('Collecting data for class {}'.format(j))\n",
    "\n",
    "    done = False\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.putText(frame, 'Ready? Press \"Q\" ! :)', (100, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3,\n",
    "                    cv2.LINE_AA)\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(25) == ord('q'):\n",
    "            break\n",
    "\n",
    "    counter = 0\n",
    "    while counter < dataset_size:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.imshow('frame', frame)\n",
    "        cv2.waitKey(25)\n",
    "        cv2.imwrite(os.path.join(DATA_DIR, str(j), '{}.jpg'.format(counter)), frame)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9c2cd3",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e8d2549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "import pickle\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)\n",
    "\n",
    "DATA_DIR = './data'\n",
    "data = []\n",
    "labels = []\n",
    "for dir_ in os.listdir(DATA_DIR):\n",
    "    dir_path = os.path.join(DATA_DIR, dir_)\n",
    "    if os.path.isdir(dir_path):\n",
    "        for img_path in os.listdir(dir_path):\n",
    "            data_aux = []\n",
    "            img = cv2.imread(os.path.join(dir_path, img_path))\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            results = hands.process(img_rgb)\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    for i in range(len(hand_landmarks.landmark)):\n",
    "                        x = hand_landmarks.landmark[i].x\n",
    "                        y = hand_landmarks.landmark[i].y\n",
    "                        data_aux.append(x)\n",
    "                        data_aux.append(y)\n",
    "                data.append(data_aux)\n",
    "                labels.append(dir_)\n",
    "\n",
    "f = open('data.pickle', 'wb')\n",
    "pickle.dump({'data': data, 'labels': labels}, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af7b35e",
   "metadata": {},
   "source": [
    "# Training the clasifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "344f3c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% of samples were classified correctly !\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "data_dict=pickle.load(open('./data.pickle','rb'))\n",
    "data = np.asarray(data_dict['data'])\n",
    "labels = np.asarray(data_dict['labels'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, shuffle=True, stratify=labels)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_predict = model.predict(x_test)\n",
    "\n",
    "score = accuracy_score(y_predict, y_test)\n",
    "\n",
    "print('{}% of samples were classified correctly !'.format(score * 100))\n",
    "\n",
    "f = open('model.p', 'wb')\n",
    "pickle.dump({'model': model}, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87296a6d",
   "metadata": {},
   "source": [
    "# Get output sond with text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7941e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from gtts import gTTS\n",
    "import pygame\n",
    "import io\n",
    "import tempfile\n",
    "\n",
    "# Load the model\n",
    "model_dict = pickle.load(open('./model.p', 'rb'))\n",
    "model = model_dict['model']\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize Mediapipe components\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)\n",
    "labels_dict = {0: 'Deaf', 1: 'hearing', 2: 'Thanks', 3: 'Drink', 4: 'ask', 5: 'fine', 6: 'see', 7: 'He', 8: 'Hello', 9: 'Yes', 10: 'me', 11: 'Sorry', 12: 'Know', 13: 'Eat', 14: 'You',15: 'my'}\n",
    "\n",
    "# Initialize Pygame mixer\n",
    "pygame.mixer.init()\n",
    "\n",
    "# Track the current and previous predictions\n",
    "previous_prediction = None\n",
    "audio_playing = False\n",
    "\n",
    "while True:\n",
    "    data_aux = []\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = hands.process(frame_rgb)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                x = landmark.x\n",
    "                y = landmark.y\n",
    "                data_aux.extend([x, y])\n",
    "\n",
    "    if data_aux:\n",
    "        prediction = model.predict([np.asarray(data_aux)])\n",
    "        predicted_value = int(prediction[0])\n",
    "        if predicted_value in labels_dict:\n",
    "            predicted_character = labels_dict[predicted_value]\n",
    "\n",
    "            # Check if the prediction has changed\n",
    "            if predicted_character != previous_prediction:\n",
    "                print(f\"The recognized sign is: {predicted_character}\")\n",
    "                previous_prediction = predicted_character\n",
    "\n",
    "                # Generate and play audio for the predicted sign\n",
    "                #text = f\"The recognized sign is: {predicted_character}\"\n",
    "                text = predicted_character\n",
    "                tts = gTTS(text=text, lang='en')\n",
    "\n",
    "                with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as fp:\n",
    "                    temp_filename = fp.name\n",
    "\n",
    "                tts.save(temp_filename)\n",
    "                pygame.mixer.music.load(temp_filename)\n",
    "                pygame.mixer.music.play()\n",
    "                audio_playing = True\n",
    "\n",
    "            # Display the recognized character on the frame\n",
    "            cv2.putText(frame, f'Sign: {predicted_character}', (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 3, cv2.LINE_AA)\n",
    "            #cv2.putText(frame, predicted_character, (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 3,cv2.LINE_AA)\n",
    "\n",
    "        else:\n",
    "            print(f\"Unknown prediction: {predicted_value}\")\n",
    "    else:\n",
    "        print(\"No hand landmarks detected in the current frame.\")\n",
    "        previous_prediction = None  # Reset if no landmarks are detected\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Hand Gesture Recognition', frame)\n",
    "\n",
    "    # Exit condition\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0ec763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
